
<!DOCTYPE html>

<head>
  <meta charset="utf-8" />
  <title>DeepModal</title>
  <meta content="DeepModal." name="description" />
  <meta content="DeepModal Networks" property="og:title" />
  <meta content="DeepModal" property="og:description" />
  <meta content="width=device-width, initial-scale=1" name="viewport" />
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
    integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
  <script src="./google.js" type="text/javascript"></script>
  <script
    type="text/javascript">WebFont.load({ google: { families: ["Lato:100,100italic,300,300italic,400,400italic,700,700italic,900,900italic", "Montserrat:100,100italic,200,200italic,300,300italic,400,400italic,500,500italic,600,600italic,700,700italic,800,800italic,900,900italic", "Ubuntu:300,300italic,400,400italic,500,500italic,700,700italic", "Changa One:400,400italic", "Open Sans:300,300italic,400,400italic,600,600italic,700,700italic,800,800italic", "Varela Round:400", "Bungee Shade:regular", "Roboto:300,regular,500"
          ,"Radio Canada", "Source Sans Pro", "Roboto Slab"] } });</script>

  <style>
    body {
      font-family: 'Microsoft Yahei' !important;
      text-align: center;
    }
    .all-wrap {
      margin: 0 auto;
      width: 65%;
    }
    .title {
      font-family: 'Radio Canada';
      color: #3c3c3c;
      font-weight: 800;
      font-size: 3vw;
      line-height: 1.3;
      margin-top: 3vw;
    }
    .subheader {
        font-family: 'Open Sans',sans-serif;
        color: #333;
        font-weight: 700;
        font-size: 1.5vw;
        margin-top: 1vw;
        margin-bottom: 1.5vw;
    }
    .affiliation{
      display: inline;
      font-family: Ubuntu,Helvetica,sans-serif;
      color: #333;
      font-size: 1.2vw;
      font-weight: 400;
      letter-spacing: 0;
    }

    .teaser {
        max-width: 100%;
    }

    .container-row {
      width: 100%;
      box-sizing: border-box;
    }

    .icon-img-container {
      position: relative;
      float: left;
      width: 33.333%;
      box-sizing: border-box;
      margin-top: 1.6vw;
    }

    .icon-text-container {
      position: relative;
      float: left;
      width: 33.333%;
      box-sizing: border-box;
      margin-bottom: 1.6vw;
    }
    .icon-img{
      width: 25%;
      filter: contrast(88%);
      opacity: .77;
    }

    .icon-text{
      font-family: 'Open Sans',sans-serif;
      font-size: 0.75vw;
      font-weight: 550;
    }

    .section-title {
      text-transform: uppercase;
      font-family: 'Radio Canada';
      color: #3c3c3c;
      font-size: 2vw;
      font-weight: 800;
      line-height: 1.3;

    }
    .long-text {
      font-family: 'Source Sans Pro';
      font-size: 1.3vw;
      font-weight: 500;
      line-height: 1.2;
      text-align: justify;
    }

    .grey_container {
      background-color: #f2f2f2;
    }

    .bibtex {
      text-align:left; 
      margin-left: 2vw; 
      font-size: larger;
      font-size: 1.2vw;
    }

  </style>
</head>

<body>
  <div class="all-wrap">
        <h1 class="title">Deep-Modal: Real-Time Impact Sound Synthesis for Arbitrary Shapes</h1>
        <h1 class="subheader">ACMMM2020</h1>
        <div>
          <h1 class="affiliation" style="margin-right: 20px;">Xutong Jin<sup>1</sup></h1>
          <h1 class="affiliation" style="margin-right: 20px;"><a href="http://www.graphics.pku.edu.cn/members/lisheng/index.htm"> Sheng Li </a> <sup>1</sup></h1>
          <h1 class="affiliation" style="margin-right: 20px;">Tianshu Qu<sup>1</sup></h1>
          <h1 class="affiliation" style="margin-right: 20px;">Dinesh Manocha<sup>2</sup></h1>
          <h1 class="affiliation" style="margin-right: 20px;">Guoping Wang<sup>1</sup></h1>
          
        </div>

        <div style="margin-top: 0.4vw;margin-bottom: 1vw;">
          <h1 class="affiliation" style="margin-right: 40px"><sup>1</sup>Peking University</h1>
          <h1 class="affiliation"><sup>2</sup>University of Maryland</h1>
        </div>

        <div>
          <span class="center" ><img class="teaser" src="images/teaser.png"></span>
        </div>

        <div class="container-row">
          <div class="icon-img-container">
            <a href="./ACMMM20_ModalSound.pdf">
              <img src="./images/paper.png" alt="paper" class="icon-img" />
            </a>
          </div>
          <div class="icon-img-container">
            <a href="https://github.com/hellojxt/NeuralSound">
              <img src="./images/github.png" alt="github"
                class="icon-img" />
            </a>
          </div>
          <div class="icon-img-container">
            <a href="./sound material.zip">
              <img src="./images/zip.png" alt="github"
                class="icon-img" />
            </a>
          </div>
        </div>

        <div class="container-row">
          <div class="icon-text-container">
            <strong class="icon-text">Paper</strong>
          </div>
          <div class="icon-text-container">
            <strong class="icon-text">Github Code</strong>
          </div>
          <div class="icon-text-container">
            <strong class="icon-text">Supplementary Materials</strong>
          </div>
        </div>


        <div class="container-row">
          <video loop="" playsinline="" controls="" width="100%" poster="./images/poster.png">
            <source src="./Deep-Modal_ Real-Time Impact Sound Synthesis for Arbitrary Shapes.mp4" type="video/mp4">
          </video>
        </div>
        
        <hr>

        <div class="w-container">
          <h2 class="section-title">Abstract</h2>
          <p class="long-text">Model sound synthesis is a physically-based sound synthesis method used to generate audio content in games and virtual worlds. We present a novel learning-based impact sound synthesis algorithm called Deep-Modal. Our approach can handle sound synthesis for common arbitrary objects, especially dynamic generated objects, in real-time. We present a new compact strategy to represent the mode data, corresponding to frequency and amplitude, as fixed-length vectors. This is combined with a new network architecture that can convert shape features of 3D objects into mode data. Our network is based on an encoder-decoder architecture with the contact positions of objects and external forces embedded. Our method can synthesize interactive sounds related to objects of various shapes at any contact position, as well as objects of different materials and sizes. The synthesis process only takes ~0.01s on a GTX 1080 Ti GPU. We show the effectiveness of Deep-Modal through extensive evaluation using different metrics, including recall and precision of prediction, sound spectrogram, and a user study.
          </p>
        </div>
        <hr>

        <h2 class="section-title">Bibtex</h2>
        <div class="grey_container">
          <div class="bibtex">
            <pre><code>
@inproceedings{jin2020deep,
    title={Deep-modal: real-time impact sound synthesis for arbitrary shapes},
    author={Jin, Xutong and Li, Sheng and Qu, Tianshu and Manocha, Dinesh and Wang, Guoping},
    booktitle={Proceedings of the 28th ACM International Conference on Multimedia},
    pages={1171--1179},
    year={2020}
}
            </code></pre>
          </div>
        </div>

    </div>

</body>

</html>
